---
title: Grafana Stack üìà 1. Observabilit√© avec Spring Boot 3
date: 2023-06-10
# modified: 2021-11-04
summary: |
    Spring Boot 3 vient avec quelques nouvelles fonctionnalit√©s dont l‚Äôobservabilit√©. Grace √† Reactor et √† Micrometer, il est tr√®s simple de mettre en place des m√©triques afin de suivre le comportement d‚Äôune application Spring Boot. Et gr√¢ce √† la stack Grafana, il sera facile de la visualiser.
categories: [observabilit√©]
tags: [spring, grafana, java, infra]
image: feature-grafana-stack-spring-boot-3-observability.webp
toc: true
# comment: /s/3cwxdp/am_liorations_et_bonnes_pratiques_pour_le
---

√Ä mes heures perdues, je travaille sur une application de veille techno qui me permet de faire la mienne <em>(veille)</em> comme j‚Äôai envie. R√©cemment, j‚Äôai entendu parler d‚Äô<strong>[Opentelemetry](https://opentelemetry.io/) un collecteur de t√©l√©m√©trie</strong>. Et j‚Äôai eu envie de le tester pour voir si je pouvais rendre mon application observable.

{{< figimg src="leasure_techwatch.svg" float="right" alt="Veille techno en temps libre" >}}
Il existe une multitude de stack de t√©l√©m√©trie, mais Grafana est open source et permet d‚Äôavoir assez facilement toutes les m√©triques sur la m√™me application de rendu. De plus, je voulais essayer [Loki](https://grafana.com/oss/loki/) en comparaisons de <abbr title="Elastic Logstash Kibana">ELK</abbr> que j‚Äôutilise d√©j√† au travail.

Voil√† donc une s√©rie d‚Äôarticles d√©taillants comment <strong>mettre en place l‚Äôobservabilit√© sur une application Spring Boot 3</strong>.

**Les autres articles de la s√©rie¬†:**

1. Observabilit√© avec Spring Boot 3
2. [Collecte des m√©triques avec OpenTelemetry]({{< relref "grafana-stack-2-collect-metrics-otel" >}})
3. [Collecte des logs avec OpenTelemetry]({{< relref "grafana-stack-3-collect-logs-otel" >}})
4. [D√©ploiement d‚Äôun Grafana]({{< relref "grafana-stack-4-grafana" >}})

## La Stack Grafana

Avant de commencer, parlons un peu de la stack grafana. Elle est compos√©e de plusieurs √©l√©ments. Dans mon boulot pr√©c√©dent et dans mon poste actuel, j‚Äôai beaucoup travaill√© avec la stack <abbr title="Elastic Logstash Kibana">ELK</abbr>. Elle est tr√®s efficace, mais j‚Äôai toujours trouv√© qu‚Äôelle √©tait compliqu√©e √† mettre en place et √† configurer. C‚Äôest l‚Äôoccasion de tester la stack Grafana plus simple √† mettre en ≈ìuvre.

### Prometheus
{{< figimg src="prometheus_god_fire.svg" float="left" alt="Prometheus √† vol√© le feu aux dieux" >}}
<strong>[Prometheus](https://prometheus.io/) est le moteur de stockage de m√©triques</strong>. Il s‚Äôagit d‚Äôun moteur de m√©triques dimensionnel. Chaque m√©trique est repr√©sent√©e par un nom et par des attributs, un ensemble de cl√©/valeur qui sp√©cialise la donn√©e. Cela permet de faire des requ√™tes puissantes, mais il faut faire attention √† <strong>ne pas avoir d‚Äôattributs dont l‚Äôensemble de valeurs possible est trop important</strong> sans quoi les performances et l‚Äôespace de stockage vont exploser.

<p class="clear-both"></p>

### Loki
<strong>[Loki](https://grafana.com/oss/loki/) est le moteur de stockage de logs</strong>. Mais, contrairement √† Elastic qui va indexer tout le contenu des logs, Loki ne va indexer que certains attributs. Loki stocke les logs comme prometheus les m√©triques. Chaque log poss√®de un ensemble d‚Äôattributs cl√©/valeur qui sont index√©s, le reste du message ne l‚Äôest pas. Comme pour les m√©triques on ne doit pas utiliser d‚Äôattribut avec un ensemble de valeurs trop grand sous peine de probl√®mes de performance et d‚Äôexplosion du stockage. L‚Äôint√©r√™t de cette approche est que l‚Äôempreinte sur le disque est bien plus faible que pour un Elastic. L‚Äôinconv√©nient est qu‚Äô<strong>il n‚Äôest pas possible de faire de recherche sur les champs non index√©s</strong> et donc sur le contenu du message de log.

### Tempo
[Tempo](https://grafana.com/oss/tempo/) quant √† lui, va stocker les traces. C‚Äôest-√†-dire le moyen de rapprocher les logs et les m√©triques dans un environnement micro-service. Cela fera l‚Äôobjet d‚Äôun autre article.

### Grafana
Enfin [Grafana](https://grafana.com/grafana/) propose une interface unifi√©e pour visualiser toute cette t√©l√©m√©trie.


## Spring Boot et l‚Äôobservabilit√©

{{< figimg src="spring_boot_observability.svg" float="right" alt="Spring observability" >}}

L‚Äôobservabilit√© regroupe les 3 √©l√©ments suivants :

* Les m√©triques
* Les logs
* Les traces

Sur les derni√®res versions du framework, l‚Äô√©quipe de Spring a ajout√© la [fonctionnalit√© d‚Äôobservabilit√©](https://spring.io/blog/2022/10/12/observability-with-spring-boot-3) qui est particuli√®rement bien int√©gr√© au mod√®le Spring Webflux et √† la programmation r√©active gr√¢ce √† Micrometer et Reactor.

Avec tr√®s peu de code additionnel il est maintenant possible d‚Äôobtenir des m√©triques d√©taill√©es pour chaque ex√©cution de stream que l‚Äôon souhaite observer.

## D√©ploiement des m√©triques

### Ajout des d√©pendences

Tout d‚Äôabord dans le `pom.xml` :

```xml
<dependency>
    <groupId>io.projectreactor</groupId>
    <artifactId>reactor-core-micrometer</artifactId>
</dependency>

<dependency>
    <groupId>io.micrometer</groupId>
    <artifactId>micrometer-registry-prometheus</artifactId>
</dependency>

<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-actuator</artifactId>
</dependency>
```

* `reactor-core-micrometer` est le plugin d‚Äôobservabilit√© de micrometer qui lui permet de s‚Äôint√©grer √† reactor.
* `micrometer-registry-prometheus` repr√©sente le format de restitution des m√©triques. En effet, il existe plusieurs approches quant √† la collecte de m√©triques. L‚Äôapproche choisie d√©termine le format de restitution. Dans notre cas, on va utiliser un Stack Grafana pour stocker et visualiser nos m√©triques, c‚Äôest donc le format prometheus (le moteur de stockage de m√©triques de grafana) qui correspond √† notre choix.
* `spring-boot-starter-actuator` l‚Äôactuator va nous permettre de mettre √† disposition un API pour collecter les m√©triques

### Configuration Spring Boot

Maintenant, il reste √† ajouter la configuration de l‚Äôactuator dans le fichier `application.yaml` :

```yaml
spring:
  application.name: MyApplication


management:
  endpoints.web.exposure.include: prometheus,health
  metrics:
    distribution.percentiles-histogram:
      http.server.requests: true
    tags:
      application: ${spring.application.name}
```

Le nom de l‚Äôapplication va permettre d‚Äôavoir un contexte dans tous les logs et toutes les m√©triques. Ainsi, si vous avez plusieurs applications spring qui g√©n√®re des m√©triques cela vous permettra de les diff√©rentier. De la m√™me fa√ßon si vous avez un cluster de plusieurs n≈ìuds, il sera int√©ressant d‚Äôajouter ici l‚Äôidentifiant du n≈ìuds.

Pour le reste, la ligne importante est `endpoints.web.exposure.include: prometheus` qui va activer l‚Äôapi de collecte pour prometheus. Le reste des param√®tres permet d'avoir un peu plus de d√©tails dans les m√©triques collect√©es.

√Ä partir de l√†, l‚Äôapplication est d√©j√† capable de fournir une grosse quantit√© de m√©triques sur le fonctionnement de Spring et de la JVM. D√©marrer l‚Äôapplication et, avec un [postman](https://www.postman.com/) par exemple, faire une requ√™te `GET /actuator/prometheus` qui est la route par d√©faut pour Prometheus.

```shell
# HELP jvm_threads_peak_threads The peak live thread count since the Java virtual machine started or peak was reset
# TYPE jvm_threads_peak_threads gauge
jvm_threads_peak_threads{context="MyApplication",} 45.0
# HELP jvm_gc_overhead_percent An approximation of the percent of CPU time used by GC activities over the last lookback period or since monitoring began, whichever is shorter, in the range [0..1]
# TYPE jvm_gc_overhead_percent gauge
jvm_gc_overhead_percent{context="MyApplication",} 0.00497286035688716
# HELP system_cpu_usage The "recent cpu usage" of the system the application is running in
# TYPE system_cpu_usage gauge
system_cpu_usage{context="MyApplication",} 0.0
# HELP process_files_max_files The maximum file descriptor count
# TYPE process_files_max_files gauge
process_files_max_files{context="MyApplication",} 1048576.0
# HELP bw_news_count Total number of News
# TYPE bw_news_count gauge
bw_news_count{context="MyApplication",} 0.0
# HELP jvm_gc_live_data_size_bytes Size of long-lived heap memory pool after reclamation
# TYPE jvm_gc_live_data_size_bytes gauge
jvm_gc_live_data_size_bytes{context="MyApplication",} 1.33460992E8
# HELP hikaricp_connections_max Max connections
# TYPE hikaricp_connections_max gauge
hikaricp_connections_max{context="MyApplication",pool="HikariPool-1",} 10.0
# HELP spring_security_authorizations_seconds  
# TYPE spring_security_authorizations_seconds summary
spring_security_authorizations_seconds_count{context="MyApplication",error="none",spring_security_authentication_type="UsernamePasswordAuthenticationToken",spring_security_authorization_decision="true",spring_security_object="exchange",} 1.0
spring_security_authorizations_seconds_sum{context="MyApplication",error="none",spring_security_authentication_type="UsernamePasswordAuthenticationToken",spring_security_authorization_decision="true",spring_security_object="exchange",} 0.005212113
```

Ce n‚Äôest qu‚Äôun exemple des m√©triques fournis de base par Spring, mais il y en a sur beaucoup d‚Äôaspects : La m√©moire, la consommation CPU, les routes appel√©es, le temps de d√©marrage, ...

### Ajout de la premi√®re m√©trique

Dans le cadre de l‚Äôapplication de veille techno, j‚Äôai un process de scraping des feed de news qui se d√©clenche toutes les heures et √ßa m‚Äôint√©resserait bien de l‚Äôobserver.

Le code de ce processus est un flux Reactor qui ex√©cute toutes les √©tapes, lanc√© √† intervales r√©guliers par un Scheduler :

```java
@Override
public void run() {
    log.info("Start scraping ...");
    scraperService.scrap(properties.conservation())
            .subscribe();
}
```

J‚Äôai simplifi√© le code r√©el, mais l‚Äôid√©e est l√†.

```java
// Injection de l‚ÄôObservationRegistry via le constructeur
private final ObservationRegistry observationRegistry;

@Override
public void run() {
    log.info("Start scraping ...");
    scraperService.scrap(properties.conservation())
            .name("bw_scraping_process")
            .tap(Micrometer.observation(observationRegistry))
            .subscribe();
}
```

Si on relance l‚Äôapplication maintenant et que l‚Äôon attend que le process de scraping se termine. Puis, que l‚Äôon interroge √† nouveau la route `GET /actuator/prometheus`. On obtient les donn√©es suppl√©mentaires suivantes.

```shell
# HELP bw_scraping_process_seconds  
# TYPE bw_scraping_process_seconds summary
bw_scraping_process_seconds_count{context="MyApplication",error="none",reactor_status="completed",reactor_type="Mono",} 1.0
bw_scraping_process_seconds_sum{context="MyApplication",error="none",reactor_status="completed",reactor_type="Mono",} 17.026397336
# HELP bw_scraping_process_seconds_max  
# TYPE bw_scraping_process_seconds_max gauge
bw_scraping_process_seconds_max{context="MyApplication",error="none",reactor_status="completed",reactor_type="Mono",} 17.026397336
# HELP bw_scraping_process_active_seconds_max  
# TYPE bw_scraping_process_active_seconds_max gauge
bw_scraping_process_active_seconds_max{context="MyApplication",reactor_type="Mono",} 0.0
# HELP bw_scraping_process_active_seconds  
# TYPE bw_scraping_process_active_seconds summary
bw_scraping_process_active_seconds_active_count{context="MyApplication",reactor_type="Mono",} 0.0
bw_scraping_process_active_seconds_duration_sum{context="MyApplication",reactor_type="Mono",} 0.0
```

L‚Äôobservabilit√© de reactor produit en tout 2 groupes de 3 m√©triques :

* Les m√©triques d‚Äôex√©cution
  * le nombre total d‚Äôappels
  * la dur√©e maximale
  * la somme des dur√©es
* Les m√©triques d‚Äôex√©cution longue (active) qui donne les m√™mes compteurs pour des op√©rations de plus longues dur√©es qui ne seraient pas termin√©es.

### Utilisation d‚Äôune Gauge

Ces m√©triques sont pratiques, mais pas simple √† interpr√©ter. Finalement, si vous souhaitez voir l‚Äô√©volution de la dur√©e du scraping au fil du temps, cela n‚Äôest pas possible. Au mieux, vous avez la dur√©e moyenne. C‚Äôest pour cela qu‚Äôil peut √™tre int√©ressant de d√©clarer une Gauge qui va permettre cette observation.

```java
private final AtomicLong lastScrapingDuration = new AtomicLong(0);

public ScraperTaskScheduler(MeterRegistry registry) {
    TimeGauge.builder("bw_scraping_process", lastScrapingDuration::get, TimeUnit.MILLISECONDS)
            .description("Last scraping duration")
            .register(registry);
}

@Override
public void run() {
    log.info("Start scraping ...");
    long startTime = System.currentTimeMillis();
    scraperService.scrap(properties.conservation())
            .doFinally(s -> lastScrapingDuration.set(System.currentTimeMillis() - startTime))
            .subscribe();
}
```

Les `TimeGauge` permettent d‚Äôajouter au compteur une unit√© de temps.

Maintenant si on relance l‚Äôapplication pour voir les compteurs, voil√† ce que l‚Äôon a.

```shell
# HELP bw_scraping_process_seconds Last scraping duration
# TYPE bw_scraping_process_seconds gauge
bw_scraping_process_seconds{context="MyApplication",} 14.201
```

Ce n‚Äôest pas flagrant comme changement mais, dans le cas d‚Äôune gauge, chaque nouvelle valeur vient remplacer la pr√©c√©dente. Contrairement √† un timer ou un compteur qui additionne chaque nouvelle valeur avec la pr√©c√©dente.

### Ajout du contexte

Il est possible d‚Äôajouter du contexte dans les m√©triques programmatiquement en utilisant le `MeterRegistryCustomizer`. Il sera cependant plus simple d‚Äôutiliser les param√®tres de configuration vu au d√©but de cet article.

```java
@Configuration
public class SpringConfiguration {
    @Bean
    public MeterRegistryCustomizer<MeterRegistry> metricsCommonTags(@Value("${spring.application.name}") String application) {
        return registry -> registry.config()
                .commonTags("context", application.toLowerCase());
    }
}
```

### S√©curisation

Dernier point important, la s√©curisation du point d‚Äôacc√®s aux m√©triques. <strong>Pensez √† s√©curiser ce point d'acc√®s</strong>, m√™me si y acc√©der ne suffira pas √† pirater l‚Äôapplication, les m√©triques laissent passer bon nombre d‚Äôinformations exploitables qui permettrait √† une personne mal intentionn√©e de d√©nicher d‚Äô√©ventuelles failles de s√©curit√©s.

## Am√©lioration des logs

{{< figimg src="improve_logs.svg" float="left" alt="Logs de spring boot en JSON" >}}
Les logs par d√©faut de Spring sont vraiment appr√©ciables et bien format√©s. Mais des logs au format texte restent un enfer √† parser. Tous ceux qui ont travaill√© un peu avec Logstash ont leurs collections de grok bien au chaud pour ce genre de chose.

Le plus simple est de faire en sorte que Spring sorte les logs en JSON, d√©j√† pars√©, elles seront directement lisibles par le collecteur. L‚Äôid√©al serait que l‚Äôon puisse r√©gler √ßa gr√¢ce √† une variable d‚Äôenvironnement, ce qui permettrait de garder les logs <em>"humain"</em> pendant le d√©veloppement et d‚Äôutiliser le json pour la production.

Logback poss√®de un plugin qui permet d‚Äôobtenir ce r√©sultat.

### Ajouter les d√©pendances

```xml
<dependency>
    <groupId>ch.qos.logback.contrib</groupId>
    <artifactId>logback-json-classic</artifactId>
    <version>0.1.5</version>
</dependency>
<dependency>
    <groupId>ch.qos.logback.contrib</groupId>
    <artifactId>logback-jackson</artifactId>
    <version>0.1.5</version>
</dependency>
```

### Configuration logback

Ensuite on configure logback comme suit dans un fichier `logback-spring.xml`:

```xml
<?xml version="1.0" encoding="UTF-8"?>
<configuration>
    <include resource="org/springframework/boot/logging/logback/defaults.xml"/>
    <springProperty scope="context" name="appName" source="spring.application.name"/>
    <springProperty scope="context" name="rootLevel" source="logging.level.root"/>

    <springProfile name="json-logging">
        <contextName>${appName}</contextName>
        <appender name="CONSOLE" class="ch.qos.logback.core.ConsoleAppender">
            <layout class="ch.qos.logback.contrib.json.classic.JsonLayout">
                <jsonFormatter class="ch.qos.logback.contrib.jackson.JacksonJsonFormatter"/>
                <timestampFormat>${LOG_DATEFORMAT_PATTERN:-yyyy-MM-dd'T'HH:mm:ss.SSS'Z'}</timestampFormat>
                <appendLineSeparator>true</appendLineSeparator>
                <prettyPrint>false</prettyPrint>
            </layout>
        </appender>
        <statusListener class="ch.qos.logback.core.status.NopStatusListener" />
    </springProfile>

    <springProfile name="!json-logging">
        <include resource="org/springframework/boot/logging/logback/console-appender.xml"/>
    </springProfile>

    <root level="${rootLevel}">
        <appender-ref ref="CONSOLE"/>
    </root>
</configuration>
```

L‚Äôint√©r√™t de cette <strong>configuration</strong>, c'est qu‚Äôelle est <strong>attach√©e au profil</strong>. Il est donc facile de passer de cette configuration √† la configuration par d√©faut des logs via la variable d'environnement `SPRING_PROFILES_ACTIVE=json-logging`.

√Ä noter l‚Äôutilisation de `spring.application.name` que l‚Äôon a mis √† jour dans les propri√©t√©s de l‚Äôapplication et qui va se retrouver dans le contexte. Ce qui permettra de distinguer les logs de notre application d‚Äôautres logs dans loki et qui mettra ainsi le m√™me contexte sur nos m√©triques et sur les logs.

### Relancer l‚Äôapplication

Si on relance l‚Äôapplication avec la configuration que l‚Äôon vient de mettre en place, voil√† ce que cela va donner :

```shell
{"timestamp":"2023-05-30T23:07:12.880Z","level":"INFO","thread":"main","logger":"fr.ght1pc9kc.myapp.MyApplication","message":"Starting MyApplication using Java 17.0.6 with PID 31428 ( started by marthym in )","context":"MyApplication"}
{"timestamp":"2023-05-30T23:07:12.893Z","level":"DEBUG","thread":"main","logger":"fr.ght1pc9kc.myapp.MyApplication","message":"Running with Spring Boot v3.1.0, Spring v6.0.9","context":"MyApplication"}
{"timestamp":"2023-05-30T23:07:12.894Z","level":"INFO","thread":"main","logger":"fr.ght1pc9kc.myapp.MyApplication","message":"The following 1 profile is active: \"json-logging\"","context":"MyApplication"}
{"timestamp":"2023-05-30T23:07:13.973Z","level":"INFO","thread":"main","logger":"org.flywaydb.core.internal.license.VersionPrinter","message":"Flyway Community Edition 9.16.3 by Redgate","context":"MyApplication"}
{"timestamp":"2023-05-30T23:07:13.973Z","level":"INFO","thread":"main","logger":"org.flywaydb.core.internal.license.VersionPrinter","message":"See release notes here: https://rd.gt/416ObMi","context":"MyApplication"}
{"timestamp":"2023-05-30T23:07:13.973Z","level":"INFO","thread":"main","logger":"org.flywaydb.core.internal.license.VersionPrinter","message":"","context":"MyApplication"}
{"timestamp":"2023-05-30T23:07:13.980Z","level":"INFO","thread":"main","logger":"com.zaxxer.hikari.HikariDataSource","message":"HikariPool-1 - Starting...","context":"MyApplication"}
{"timestamp":"2023-05-30T23:07:14.067Z","level":"INFO","thread":"main","logger":"com.zaxxer.hikari.pool.HikariPool","message":"HikariPool-1 - Added connection org.sqlite.jdbc4.JDBC4Connection@6f8667bb","context":"MyApplication"}
{"timestamp":"2023-05-30T23:07:14.068Z","level":"INFO","thread":"main","logger":"com.zaxxer.hikari.HikariDataSource","message":"HikariPool-1 - Start completed.","context":"MyApplication"}
```

Beaucoup plus difficile √† lire pour un humain, mais bien plus simple √† parser.

## Conclusion

Voil√† les quelques am√©liorations √† mettre en place dans une application Spring pour simplifier la collecte des m√©triques. Dans le prochain article, nous verrons comment mettre en place un collecteur OpenTelemetry et r√©cup√©rer les m√©triques que l‚Äôon vient de configurer.
