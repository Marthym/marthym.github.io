---
title: Grafana Stack üìà 2. Collecte des m√©triques avec OpenTelemetry
date: 2023-06-18
# modified: 2021-11-04
summary: |
    Maintenant que l‚Äôapplication Spring Boot pr√©sente des m√©triques, il est n√©cessaire de les collecter. Les m√©triques seront stock√©s dans Prometheus mais pour les collecter, nous allons utiliser OpenTelemetry.
tags: [otel, ansible, prometheus, metriques, devops]
image: feature-grafana-stack-open-telemetry.webp
toc: true
# comment: /s/3cwxdp/am_liorations_et_bonnes_pratiques_pour_le
---

Dans l‚Äô[article pr√©c√©dent]({{< relref "grafana-stack-1-spring-observability" >}}), nous avons activ√© l‚Äôobservabilit√© de Spring Boot 3 et vu comment ajouter des m√©triques personnalis√©es √† une application.

Maintenant, il est n√©cessaire de collecter ces m√©triques et de les stocker avant de pouvoir les afficher dans Grafana.

**Les autres articles de la s√©rie¬†:**

1. [Observabilit√© avec Spring Boot 3]({{< relref "grafana-stack-1-spring-observability" >}})
2. Collecte des m√©triques avec OpenTelemetry
3. [Collecte des logs avec OpenTelemetry]({{< relref "grafana-stack-3-collect-logs-otel" >}})

## OpenTelemetry

{{< figimg src="open-telemetry.webp" float="right" alt="Liste des cibles de prometheus" >}}
[OpenTelemetry](https://opentelemetry.io/) est un collecteur de ... t√©l√©m√©trie. Cela inclut les m√©triques, les logs et les traces. Mais OpenTelemetry, c‚Äôest aussi une communaut√© qui essaye de d√©crire une [sp√©cification](https://opentelemetry.io/docs/specs/otel/overview/) pour d√©finir la m√©trologie. Par exemple, la sp√©cification propose des [conventions](https://github.com/open-telemetry/semantic-conventions) pour les noms de m√©triques.

## Pr√©requis au d√©ploiement

### Docker Compose

L‚Äôapplication que l‚Äôon a prise comme exemple dans l‚Äô[article pr√©c√©dent]({{< relref "grafana-stack-1-spring-observability" >}}) est d√©ploy√©e via [docker-compose](https://docs.docker.com/compose/). Un script Ansible automatise le d√©ploiement de la configuration du service sur le serveur et il suffit de faire un `dc up -d` pour d√©marrer l‚Äôapplication et tous les services d√©pendants en production.

On va rester sur la m√™me techno pour d√©ployer la collecte des t√©l√©m√©tries.

### Service prometheus

Comme expliqu√© dans l‚Äôarticle pr√©c√©dent, les m√©triques seront stock√©es par un serveur [Prometheus](https://prometheus.io/). Il faut donc commencer par en d√©ployer un. Rien de compliqu√© pour ce composant, voil√† la d√©claration du service dans le compose.

```yaml {hl_lines=["8"]}
services:
  prometheus:
    image: prom/prometheus:v2.44.0
    restart: unless-stopped
    command:
    - --config.file=/etc/prometheus/prometheus.yml
    - --storage.tsdb.path=/prometheus
    # - --storage.tsdb.retention.time=90d
    - --web.console.libraries=/usr/share/prometheus/console_libraries
    - --web.console.templates=/usr/share/prometheus/consoles
    volumes:
    - /opt/bw/prometheus/:/etc/prometheus/
    - prometheus_data:/prometheus
    networks:
      metrics: {}

volumes:
  prometheus_data: {}

networks:
  metrics: {}

```

Par d√©faut Prometheus garde les donn√©es pendant 15 jours. Il peut √™tre int√©ressant d‚Äô√©tendre la dur√©e de r√©tention √† 90 jours ou plus. Pour cela ajouter l‚Äôoptions `storage.tsdb.retention.time=` √† la ligne de commande.

Prometheus se configure au travers d‚Äôun unique fichier `prometheus.yml` pass√© en param√®tre de la ligne de commande dans le dockerfile ci-dessus. Les param√®tres de configuration sont d√©taill√©s dans la [documentation](https://prometheus.io/docs/prometheus/latest/configuration/configuration/), voil√† le fichier utilis√© pour notre application.

```yaml {hl_lines=["20"]}
---

global:
  scrape_interval:     15s # By default, scrape targets every 15 seconds.
  evaluation_interval: 15s # By default, scrape targets every 15 seconds.
  # scrape_timeout is set to the global default (10s).

# A scrape configuration containing exactly one endpoint to scrape:
# Here it's Prometheus itself.
scrape_configs:

  # Le job pour se collecter lui m√™me (optionel)
  - job_name: 'prometheus'
    static_configs:
      - targets: ['localhost:9090']

  # Le job de collecte OpenTelemetry
  - job_name: 'otel-exporter'
    scrape_interval: 15s
    file_sd_configs:
      - files:
        - 'targets/otel_targets.yml'
```


enfin, `targets/otel_targets.yml`.
{{< figimg src="otel-observability-satellite.webp" float="right" alt="test" >}}

```yaml
---

- targets:
  - 'opentelemetry:9091'
```

L‚Äôint√©r√™t de passer par `file_sd_configs` est que Prometheus va pouvoir faire du **hot reload** quand le fichier de cibles sera mis √† jour. **Il ne sera pas n√©cessaire de red√©marrer le serveur pour ajouter une cible**.

D√©tail important, le service `prometheus` est plac√© dans un r√©seau `metrics`, ce qui l‚Äôisolera du r√©seau sur lequel l‚Äôapplication est plac√©e. C‚Äôest le service `opentelemetry` qui fera le lien entre les deux sous-r√©seaux de docker.

## Service OpenTelemetry

Il √©tait possible et s√ªrement plus simple de configurer le prometheus pour aller scraper directement l‚Äôapplication. Mais c‚Äôest aussi beaucoup moins √©volutif. En effet, dans le cas d‚Äôinfrastructure r√©seau plus complexe, un collecteur OpenTelemetry peu servir de collecteur interm√©diaire. De plus OTEL vient avec toute une panoplie de fonctionnalit√© pour la collecte et le traitement des m√©triques qui vont grandement simplifier certaines √©tapes lorsque l‚Äôon ajoutera les logs et les traces.

{{< figimg src="schema-docker-compose.svg" alt="Liste des cibles de prometheus" caption="L‚Äôinfrastructure une fois le prometheus d√©ploy√©" >}}
<br>

La version "standard" d‚ÄôOpenTelemetry ne contient que les fonctionnalit√©s de base. Pour mettre en place toute une stack de m√©trologie, il sera plus int√©ressant d‚Äôutiliser la distribution `contrib` qui vient avec un ensemble de plugins permettant de s‚Äôinterfacer avec √† peu pr√®s tout.

https://github.com/open-telemetry/opentelemetry-collector-contrib

### Configuration OpenTelemetry

OTEL se configure en 4 √©tapes :

* Les receveurs, qui r√©cup√®rent la m√©trologie
* Les processeurs, qui traitent et transforment les √©v√©nements
* Les exporteurs, qui renvoient les √©v√©nements vers leurs points de stockage
* Le service, qui relie et ordonne les pr√©c√©dentes configurations

```yaml
receivers:
  prometheus/myapp:
    config:
      scrape_configs:
        - job_name: 'otel-collector'
          scrape_interval: 15s
          metrics_path: '/actuator/prometheus'
        #   Si vous avez s√©curis√© la route comme pr√©cognis√© dans l‚Äôarticle pr√©c√©dent
        #   basic_auth:
        #     username: "otel_collector"
        #     password: "otel_password"
          static_configs:
            - targets: [myappservice:8081]
              labels:
                platform: 'prod'
```

On utilise le [Prometheus Receiver](https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/receiver/prometheusreceiver) qui va scraper la route de m√©trique de notre application au format prometheus. La configuration se fait exactement de la m√™me fa√ßon que pour un scraper prometheus normal.

√Ä noter que Spring poss√®de un exporteur vers OTEL et serait donc capable d‚Äôenvoyer directement la t√©l√©m√©trie vers ce dernier. J‚Äôaime moins cette approche, car elle rend **l‚Äôapplication consciente de l‚Äôexistence du collecteur**. Changer de collecteur demanderait de changer la configuration de l‚Äôapplication et cr√©e une sorte de d√©pendance.

```yaml
processors:
  batch:
    send_batch_size: 10000
    send_batch_max_size: 11000
    timeout: 10s
```

Parmi les bonnes pratiques OTEL, il est conseill√© de toujours utiliser le [Batch Processor](https://github.com/open-telemetry/opentelemetry-collector/blob/main/processor/batchprocessor/README.md), il va permettre de batcher les envoies de m√©triques et autres pour ne pas multiplier le nombre de connexions au serveur de destination.

```yaml
exporters:
  prometheus:
    endpoint: '0.0.0.0:9091'
    send_timestamps: true
    enable_open_metrics: true
```

Le [Prometheus Exporter](https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/exporter/prometheusexporter) va mettre √† disposition d‚Äôun scraper les m√©triques r√©cup√©r√©es au format prometheus.

Le endpoint permet de d√©terminer l‚Äôinterface r√©seau utilis√© pour d√©ployer la route de collecte et le port. `0.0.0.0` d√©ploie la route de collecte sur toutes les interfaces r√©seaux.

```yaml
service:
  pipelines:
    metrics:
      receivers: [prometheus/myapp]
      processors: [batch]
      exporters: [prometheus]

```

On d√©clare le pipeline pour les m√©triques en assemblant toutes les configurations que l‚Äôon vient de faire.

### Service compose

```yaml
services:
  opentelemetry:
    image: otel/opentelemetry-collector-contrib:0.77.0
    user: 0:0
    command:
    - --config=/etc/otel/receivers.yaml
    - --config=/etc/otel/processors.yaml
    - --config=/etc/otel/exporters.yaml
    - --config=/etc/otel/service.yaml
    logging:
      driver: local
      options:
        max-size: 10m
    volumes:
    - /opt/opentelemetry:/etc/otel:ro
    networks:
      myappnet: {}
      metrics: {}

networks:
  metrics: {}
  myappnet: {}
```

On utilise l‚Äôimage `opentelemetry-collector-contrib` qui contient tous les plugins suppl√©mentaires dont on a besoin.

Dans la `command` on inclut les fichiers de configuration que l‚Äôon vient de cr√©er.

On place le service dans le r√©seau `metrics` pour que le service `prometheus` le voit et dans le r√©seau `myappnet` pour qu‚Äôil puisse se connecter √† `myappservice:8081` que l‚Äôon a d√©clar√© dans le scraper.

On monte un volume en lecture seule pour acc√©der aux fichiers de configurations.

{{< figimg src="open-telemetry-configuration.webp" alt="Image contrib pour open telemetry" >}}
**L‚Äôensemble des fichiers de configuration est disponible sur [github](https://gist.github.com/Marthym/320fb102c473c17ee31367a067988800).**

Une fois la configuration en place, un `dc up -d` devrait d√©marrer tous les services et commencer la collecte des m√©triques.

## V√©rifications et debugging

√Ä ce stade, √©tant donn√© qu‚Äôil n‚Äôy a pas encore d‚Äôinterface pour visualiser les m√©triques, il n‚Äôest pas facile de voir ce qu‚Äôil se passe sous le capot et de comprendre ce qu‚Äôil se passe quand un probl√®me survient.

### Interface Prometheus

Prometheus poss√®de une interface capable de visualiser certains √©l√©ments comme les valeurs des m√©triques recueilli ou la liste des cibles de scraping.

{{< figimg src="prometheus-target-list.webp" alt="Liste des cibles de prometheus" caption="Liste des cibles de prometheus" >}}

### Open Telemetry en verbose

Autre astuce qui peut servir, mettre OpenTelemetry en **verbose**. Cela se fait gr√¢ce au [Logging Exporter](https://github.com/open-telemetry/opentelemetry-collector/blob/main/exporter/loggingexporter/README.md).

```yaml
exporters:
  logging:
    verbosity: detailed
```

En l‚Äôajoutant au pipeline, Open Telemetry va cracher beaucoup de logs, vraiment beaucoup. Chaque m√©trique y sera d√©taill√©e. C‚Äôest tr√®s pratique mais, on se noie rapidement dans la masse de logs qui sortent.

## Conclusion

Nous avons mis en place un collecteur et de quoi stocker les m√©triques de notre application. Gr√¢ce √† Open Telemetry les m√©triques de notre application sont bien au chaud dans Prometheus.

Dans l‚Äôarticle suivant, nous ferons la m√™me chose avec **les logs de l‚Äôapplication**.
