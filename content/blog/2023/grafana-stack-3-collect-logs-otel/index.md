---
title: Grafana Stack üìà 3. Collecte des logs avec OpenTelemetry
date: 2023-07-03
# modified: 2021-11-04
summary: |
    Les m√©triques sont bien au chaud dans prometheus. On va pouvoir collecter les logs applicatives avec OpenTelemetry. Grace au plugin logback que nous avons configurer dans Spring Boot, les logs sortent en JSON et il n‚Äôest pas n√©cessaire de les parser avant de les pousser dans Loki.
tags: [otel, ansible, loki, logs, devops]
image: feature-grafana-stack-open-telemetry.webp
toc: true
# comment: /s/3cwxdp/am_liorations_et_bonnes_pratiques_pour_le
---

Dans l‚Äô[article pr√©c√©dent]({{< relref "grafana-stack-2-collect-metrics-otel" >}}), nous avons collect√© les m√©triques de l‚Äôapplication Spring. Reste maintenant √† collecter les logs de cette application. Gr√¢ce √† la confguration de Logback que l‚Äôon a mis en place dans le [premier article]({{< relref "grafana-stack-1-spring-observability" >}}), les logs de Spring sortent au formta JSON, ce qui va grandement simplifier les pipeline de collecte.

**Les autres articles de la s√©rie¬†:**

1. [Observabilit√© avec Spring Boot 3]({{< relref "grafana-stack-1-spring-observability" >}})
2. [Collecte des m√©triques avec OpenTelemetry]({{< relref "grafana-stack-2-collect-metrics-otel" >}})
3. Collecte des logs avec OpenTelemetry

## Pr√©requis au d√©ploiement
{{< figimg src="loki-as-logs-storage.webp" alt="Loki comme stockage des logs" credit="Loki (Tom Hiddleston) dans la s√©rie de Disney+, cr√©√©e par Michael Waldron et r√©alis√©e par Kate Herron. MARVEL STUDIOS" >}}

### Docker Compose

Tout comme dans l‚Äôarticle pr√©c√©dent on va incr√©menter le fichier `docker-compose.yml` avec un nouveau service : **[Loki](https://grafana.com/oss/loki/)**.

### Service prometheus
Loki (toujours de Grafana Labs), est un moteur de stockage de logs. Sur le m√™me principe que prometheus il va permettre de conserver les logs applicatives pour les restituer via des requ√™tes LogQL. L‚Äôapproche de Loki est diff√©rentes de celle de Elastic par exemple car il ne va indexer que les meta-donn√©es des logs et non tout leur contenu.

{{< figimg src="loki-tabs-with-console.svg" alt="Stockage optimis√© Loki" >}}

Voil√† la d√©claration du service Loki dans le compose.

```yaml
services:
  loki:
    image: grafana/loki:2.8.1
    restart: unless-stopped
    command:
      - -config.file=/etc/loki/local-config.yaml
      - -config.expand-env=true
    volumes:
      - ./.compose/loki/local-config.yaml:/etc/loki/local-config.yaml
      - loki_data:/loki
    networks:
      metrics: {}

volumes:
  loki_data: {}

networks:
  metrics: {}

```

Loki se configure via le fichier `local-config.yaml` pass√© en param√®tre de la ligne de commande dans le dockerfile ci-dessus.
Les param√®tres de configuration sont d√©taill√©s dans la [documentation](https://grafana.com/docs/loki/latest/configuration/?plcmt=learn-nav), voil√† le fichier utilis√© pour notre application.

On notera dans les commandes du compose le param√®tre `-config.expand-env=true` qui autorise √† mettre des variables d‚Äôenvironnement dans le fichier de configuration suivant.

```yaml {hl_lines=["18-22"]}
---
auth_enabled: false

server:
  http_listen_port: ${LOKI_LISTEN_PORT:-3100}

common:
  path_prefix: /loki
  storage:
    filesystem:
      chunks_directory: /loki/chunks
      rules_directory: /loki/rules
  replication_factor: 1
  ring:
    kvstore:
      store: inmemory

compactor:
  retention_enabled: true

limits_config:
  retention_period: ${LOKI_RETENTION_PERIOD:-30d}

schema_config:
  configs:
    - from: 2020-10-24
      store: boltdb-shipper
      object_store: filesystem
      schema: v11
      index:
        prefix: index_
        period: 24h

ruler:
  alertmanager_url: http://localhost:9093
```

Il s‚Äôagit du fichier de configuration par d√©faut avec quelques am√©liorations tout de m√™me :

* On active une r√©tention de 30 jours par d√©faut. Sans √ßa, Loki garde les logs Ad-Vitam.
* On utilise la r√©solution de variables d‚Äôenv pour permettre de modifier les valeurs du port et la dur√©e de r√©tention.

Le stockage `filesystem` est largement suffisant pour le cas de notre application, mais il pr√©sente l‚Äôinconv√©nient de na pas √™tre scalable, contrairement √† d‚Äôautres syst√®mes propos√©s.

## Service OpenTelemetry

Il √©tait possible et s√ªrement plus simple de configurer le prometheus pour aller scraper directement l‚Äôapplication. Mais c‚Äôest aussi beaucoup moins √©volutif. En effet, dans le cas d‚Äôinfrastructure r√©seau plus complexe, un collecteur OpenTelemetry peu servir de collecteur interm√©diaire. De plus OTEL vient avec toute une panoplie de fonctionnalit√© pour la collecte et le traitement des m√©triques qui vont grandement simplifier certaines √©tapes lorsque l‚Äôon ajoutera les logs et les traces.

{{< figimg src="schema-docker-compose.svg" alt="Liste des cibles de prometheus" caption="L‚Äôinfrastructure une fois le prometheus d√©ploy√©" >}}
<br>

La version "standard" d‚ÄôOpenTelemetry ne contient que les fonctionnalit√©s de base. Pour mettre en place toute une stack de m√©trologie, il sera plus int√©ressant d‚Äôutiliser la distribution `contrib` qui vient avec un ensemble de plugins permettant de s‚Äôinterfacer avec √† peu pr√®s tout.

https://github.com/open-telemetry/opentelemetry-collector-contrib

### Configuration OpenTelemetry

OTEL se configure en 4 √©tapes :

* Les receveurs, qui r√©cup√®rent la m√©trologie
* Les processeurs, qui traitent et transforment les √©v√©nements
* Les exporteurs, qui renvoient les √©v√©nements vers leurs points de stockage
* Le service, qui relie et ordonne les pr√©c√©dentes configurations

```yaml
receivers:
  prometheus/myapp:
    config:
      scrape_configs:
        - job_name: 'otel-collector'
          scrape_interval: 15s
          metrics_path: '/actuator/prometheus'
        #   Si vous avez s√©curis√© la route comme pr√©cognis√© dans l‚Äôarticle pr√©c√©dent
        #   basic_auth:
        #     username: "otel_collector"
        #     password: "otel_password"
          static_configs:
            - targets: [myappservice:8081]
              labels:
                platform: 'prod'
```

On utilise le [Prometheus Receiver](https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/receiver/prometheusreceiver) qui va scraper la route de m√©trique de notre application au format prometheus. La configuration se fait exactement de la m√™me fa√ßon que pour un scraper prometheus normal.

√Ä noter que Spring poss√®de un exporteur vers OTEL et serait donc capable d‚Äôenvoyer directement la t√©l√©m√©trie vers ce dernier. J‚Äôaime moins cette approche, car elle rend **l‚Äôapplication consciente de l‚Äôexistence du collecteur**. Changer de collecteur demanderait de changer la configuration de l‚Äôapplication et cr√©e une sorte de d√©pendance.

```yaml
processors:
  batch:
    send_batch_size: 10000
    send_batch_max_size: 11000
    timeout: 10s
```

Parmi les bonnes pratiques OTEL, il est conseill√© de toujours utiliser le [Batch Processor](https://github.com/open-telemetry/opentelemetry-collector/blob/main/processor/batchprocessor/README.md), il va permettre de batcher les envoies de m√©triques et autres pour ne pas multiplier le nombre de connexions au serveur de destination.

```yaml
exporters:
  prometheus:
    endpoint: '0.0.0.0:9091'
    send_timestamps: true
    enable_open_metrics: true
```

Le [Prometheus Exporter](https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/exporter/prometheusexporter) va mettre √† disposition d‚Äôun scraper les m√©triques r√©cup√©r√©es au format prometheus.

Le endpoint permet de d√©terminer l‚Äôinterface r√©seau utilis√© pour d√©ployer la route de collecte et le port. `0.0.0.0` d√©ploie la route de collecte sur toutes les interfaces r√©seaux.

```yaml
service:
  pipelines:
    metrics:
      receivers: [prometheus/myapp]
      processors: [batch]
      exporters: [prometheus]

```

On d√©clare le pipeline pour les m√©triques en assemblant toutes les configurations que l‚Äôon vient de faire.

### Service compose

```yaml
services:
  opentelemetry:
    image: otel/opentelemetry-collector-contrib:0.77.0
    user: 0:0
    command:
    - --config=/etc/otel/receivers.yaml
    - --config=/etc/otel/processors.yaml
    - --config=/etc/otel/exporters.yaml
    - --config=/etc/otel/service.yaml
    logging:
      driver: local
      options:
        max-size: 10m
    volumes:
    - /opt/opentelemetry:/etc/otel:ro
    networks:
      myappnet: {}
      metrics: {}

networks:
  metrics: {}
  myappnet: {}
```

On utilise l‚Äôimage `opentelemetry-collector-contrib` qui contient tous les plugins suppl√©mentaires dont on a besoin.

Dans la `command` on inclut les fichiers de configuration que l‚Äôon vient de cr√©er.

On place le service dans le r√©seau `metrics` pour que le service `prometheus` le voit et dans le r√©seau `myappnet` pour qu‚Äôil puisse se connecter √† `myappservice:8081` que l‚Äôon a d√©clar√© dans le scraper.

On monte un volume en lecture seule pour acc√©der aux fichiers de configurations.

{{< figimg src="open-telemetry-configuration.webp" alt="Image contrib pour open telemetry" >}}
**L‚Äôensemble des fichiers de configuration est disponible sur [github](https://gist.github.com/Marthym/320fb102c473c17ee31367a067988800).**

Une fois la configuration en place, un `dc up -d` devrait d√©marrer tous les services et commencer la collecte des m√©triques.

## V√©rifications et debugging

√Ä ce stade, √©tant donn√© qu‚Äôil n‚Äôy a pas encore d‚Äôinterface pour visualiser les m√©triques, il n‚Äôest pas facile de voir ce qu‚Äôil se passe sous le capot et de comprendre ce qu‚Äôil se passe quand un probl√®me survient.

### Interface Prometheus

Prometheus poss√®de une interface capable de visualiser certains √©l√©ments comme les valeurs des m√©triques recueilli ou la liste des cibles de scraping.

{{< figimg src="prometheus-target-list.webp" alt="Liste des cibles de prometheus" caption="Liste des cibles de prometheus" >}}

### Open Telemetry en verbose

Autre astuce qui peut servir, mettre OpenTelemetry en **verbose**. Cela se fait gr√¢ce au [Logging Exporter](https://github.com/open-telemetry/opentelemetry-collector/blob/main/exporter/loggingexporter/README.md).

```yaml
exporters:
  logging:
    verbosity: detailed
```

En l‚Äôajoutant au pipeline, Open Telemetry va cracher beaucoup de logs, vraiment beaucoup. Chaque m√©trique y sera d√©taill√©e. C‚Äôest tr√®s pratique mais, on se noie rapidement dans la masse de logs qui sortent.

## Conclusion

Nous avons mis en place un collecteur et de quoi stocker les m√©triques de notre application. Gr√¢ce √† Open Telemetry les m√©triques de notre application sont bien au chaud dans Prometheus.

Dans l‚Äôarticle suivant, nous ferons la m√™me chose avec **les logs de l‚Äôapplication**.
